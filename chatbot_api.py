# chatbot_api.py - FÄ°X: Gemini Model + GeliÅŸmiÅŸ Retrieval

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from typing import List, Dict
import os
import re
import json
from rank_bm25 import BM25Okapi
from google import genai
from dotenv import load_dotenv
load_dotenv()


# ============================================================================
# KONFIGÃœRASYON
# ============================================================================

app = FastAPI(title="Mevzuat Chatbot API")

CHROMA_DIR = "./mevzuat_db"
JSON_PATH = "tum_mevzuat_maddeleri.json"

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")

# ============================================================================
# MODEL YÃœKLEMELERÄ°
# ============================================================================

print("ğŸ¤– BERTurk embedding modeli yÃ¼kleniyor...")
embeddings = HuggingFaceEmbeddings(
    model_name="dbmdz/bert-base-turkish-cased",
    model_kwargs={'device': 'cpu'},
    encode_kwargs={'normalize_embeddings': True}
)
print("âœ… BERTurk hazÄ±r!")

if not os.path.exists(CHROMA_DIR):
    raise Exception(f"âŒ ChromaDB bulunamadÄ±: {CHROMA_DIR}")

print("ğŸ“š ChromaDB yÃ¼kleniyor...")
db = Chroma(persist_directory=CHROMA_DIR, embedding_function=embeddings)
print("âœ… ChromaDB hazÄ±r!")

if not os.path.exists(JSON_PATH):
    raise Exception(f"âŒ JSON dosyasÄ± bulunamadÄ±: {JSON_PATH}")

print("ğŸ“„ Mevzuat dÃ¶kÃ¼manlarÄ± yÃ¼kleniyor...")
with open(JSON_PATH, "r", encoding="utf-8") as f:
    all_documents = json.load(f)
print(f"âœ… {len(all_documents)} madde yÃ¼klendi")

print("ğŸ“Š BM25 index oluÅŸturuluyor...")
tokenized_corpus = [doc["icerik"].lower().split() for doc in all_documents]
bm25 = BM25Okapi(tokenized_corpus)
print("âœ… BM25 hazÄ±r!")

print("ğŸ§  Gemini LLM yapÄ±landÄ±rÄ±lÄ±yor...")
try:
    # Yeni SDK
    client = genai.Client(api_key=GEMINI_API_KEY)
    MODEL_NAME = 'gemini-2.5-flash'
    print("âœ… Gemini LLM hazÄ±r!")
    gemini_available = True
except Exception as e:
    print(f"âŒ Gemini yapÄ±landÄ±rÄ±lamadÄ±: {e}")
    gemini_available = False


# ============================================================================
# PYDANTIC MODELLERÄ°
# ============================================================================

class Question(BaseModel):
    question: str
    session_id: str = "default"
    top_k: int = 5
    temperature: float = 0.3

class ChatResponse(BaseModel):
    question: str
    answer: str
    sources: list
    session_id: str

# ============================================================================
# YARDIMCI FONKSÄ°YONLAR
# ============================================================================

def normalize_text(text: str) -> str:
    """Metni normalize et"""
    text = text.lower()
    text = re.sub(r'[^\wÄŸÃ¼ÅŸÃ¶Ã§Ä±Ä°\s]', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def extract_keywords(query: str) -> List[str]:
    """
    Sorudan Ã¶nemli anahtar kelimeleri Ã§Ä±kar (stop words'leri filtrele)
    """
    # TÃ¼rkÃ§e stop words
    stop_words = {
        'bir', 'bu', 've', 'ile', 'iÃ§in', 'mi', 'mÄ±', 'mu', 'mÃ¼',
        'da', 'de', 'ta', 'te', 'ben', 'sen', 'bana', 'sana',
        'ne', 'nedir', 'nasÄ±l', 'gibi', 'olan', 'olarak',
        'verir', 'misin', 'misiniz', 'var', 'yok', 'ÅŸey',
        'hakkÄ±nda', 'konusunda', 'ile', 'alakalÄ±', 'ilgili',
        'bilgi', 'verme', 'vermek', 'sÃ¶yle', 'anlat',
        'eder', 'olur', 'dÄ±r', 'dir', 'tir', 'tÄ±r'
    }

    words = normalize_text(query).split()
    keywords = [w for w in words if w not in stop_words and len(w) > 2]

    return keywords

def hybrid_search(query: str, top_k: int = 5) -> List[Dict]:
    """
    GeliÅŸtirilmiÅŸ Hybrid Search (BM25 + Semantic + Keyword Filtering)
    """
    query_normalized = normalize_text(query)

    # Anahtar kelimeleri Ã§Ä±kar
    keywords = extract_keywords(query)
    print(f"ğŸ” Anahtar kelimeler: {keywords}")

    # 1. BM25 Search (sadece keywords ile)
    bm25_scores = bm25.get_scores(keywords)

    # 2. Semantic Search
    try:
        semantic_results = db.similarity_search_with_score(query, k=top_k * 3)
    except Exception as e:
        print(f"âš ï¸  Semantic search hatasÄ±: {e}")
        semantic_results = []

    # 3. SonuÃ§larÄ± birleÅŸtir
    candidates = {}

    # BM25 sonuÃ§larÄ±
    for idx, score in enumerate(bm25_scores):
        if score > 0:
            doc_id = f"doc_{idx}"
            candidates[doc_id] = {
                'doc': all_documents[idx],
                'bm25_score': float(score),
                'semantic_score': 0.0,
                'content': all_documents[idx]['icerik']
            }

    # Semantic sonuÃ§larÄ±
    for doc, distance in semantic_results:
        content = doc.page_content
        for idx, d in enumerate(all_documents):
            if d['icerik'] == content:
                doc_id = f"doc_{idx}"
                semantic_score = 1 - distance

                if doc_id in candidates:
                    candidates[doc_id]['semantic_score'] = semantic_score
                else:
                    candidates[doc_id] = {
                        'doc': d,
                        'bm25_score': 0.0,
                        'semantic_score': semantic_score,
                        'content': content
                    }
                break

    # 4. AKILLI KEYWORD BOOST (Ä°yileÅŸtirilmiÅŸ)
    domain_keywords = {
        'gÃ¼z': ['gÃ¼z', 'bahar', 'dÃ¶nem', 'yarÄ±yÄ±l', 'akademik takvim'],
        'bahar': ['gÃ¼z', 'bahar', 'dÃ¶nem', 'yarÄ±yÄ±l', 'akademik takvim'],
        'baÅŸvuru': ['baÅŸvuru', 'mÃ¼racaat', 'kayÄ±t', 'kabul', 'ÅŸart', 'koÅŸul'],
        'yatay': ['yatay geÃ§iÅŸ', 'dikey geÃ§iÅŸ', 'transfer', 'intibak'],
        'Ã§ift': ['Ã§ift anadal', 'Ã§ap', 'yan dal', 'yandal'],
        'yan': ['yan dal', 'yandal', 'Ã§ift anadal'],
        'staj': ['staj', 'uygulama', 'iÅŸ yeri', 'iÅŸletme'],
        'sÄ±nav': ['sÄ±nav', 'final', 'vize', 'bÃ¼tÃ¼nleme', 'mazeret'],
        'dersi': ['ders', 'kurs', 'program', 'mÃ¼fredat'],
    }

    for doc_id, result in candidates.items():
        content_lower = result['content'].lower()
        belge_lower = result['doc']['belge'].lower()

        keyword_boost = 0
        match_count = 0

        # Her keyword iÃ§in kontrol
        for kw in keywords:
            # DoÄŸrudan eÅŸleÅŸme
            if kw in content_lower:
                match_count += 1
                keyword_boost += 2.0

            # Belge adÄ±nda eÅŸleÅŸme (daha deÄŸerli)
            if kw in belge_lower:
                keyword_boost += 3.0
                match_count += 1

            # Domain keyword grubu eÅŸleÅŸmesi
            if kw in domain_keywords:
                related_words = domain_keywords[kw]
                for rel_word in related_words:
                    if rel_word in content_lower or rel_word in belge_lower:
                        keyword_boost += 1.5
                        match_count += 0.5
                        break

        # EÅŸleÅŸme oranÄ±
        if keywords:
            match_ratio = match_count / len(keywords)
            keyword_boost *= match_ratio  # DÃ¼ÅŸÃ¼k eÅŸleÅŸmeleri cezalandÄ±r

        result['keyword_boost'] = keyword_boost
        result['match_count'] = match_count

    # 5. Final Skor (Hybrid + Match Filtering)
    for doc_id in candidates:
        c = candidates[doc_id]

        # En az 1 keyword eÅŸleÅŸmesi olmalÄ±
        if c['match_count'] < 1:
            c['final_score'] = 0.0
        else:
            c['final_score'] = (
                c['bm25_score'] * 0.35 +
                c['semantic_score'] * 0.35 +
                c['keyword_boost'] * 0.30
            )

    # 6. SÄ±rala ve filtrele (0 skorlarÄ± Ã§Ä±kar)
    sorted_results = sorted(
        [c for c in candidates.values() if c['final_score'] > 0],
        key=lambda x: x['final_score'],
        reverse=True
    )

    return sorted_results[:top_k]

def create_llm_answer(results: List[Dict], query: str, temperature: float = 0.3) -> str:
    """
    Gemini LLM ile akÄ±llÄ± cevap Ã¼ret
    """
    if not results:
        return "ÃœzgÃ¼nÃ¼m, bu konuda mevzuatlarda ilgili bilgi bulamadÄ±m. LÃ¼tfen sorunuzu farklÄ± kelimelerle ifade etmeyi deneyin."

    if not gemini_available:
        return create_fallback_answer(results, query)

    # Context hazÄ±rla
    context = ""
    for i, result in enumerate(results[:3], 1):
        doc = result['doc']
        context += f"\n\n--- KAYNAK {i} ---\n"
        context += f"Belge: {doc['belge']}\n"
        context += f"Madde No: {doc['madde_no']}\n"
        if doc.get('fikra_no'):
            context += f"FÄ±kra No: {doc['fikra_no']}\n"
        context += f"Ä°Ã§erik:\n{doc['icerik']}\n"

    # Prompt
    prompt = f"""Sen SelÃ§uk Ãœniversitesi'nin mevzuat konusunda uzman bir asistansÄ±n.

GÃ–REV: AÅŸaÄŸÄ±daki mevzuat maddelerini kullanarak kullanÄ±cÄ±nÄ±n sorusunu cevapla.

KULLANICI SORUSU:
{query}

Ä°LGÄ°LÄ° MEVZUAT MADDELERÄ°:
{context}

Ã–NEMLÄ° KURALLAR:
1. **SADECE** verilen mevzuat maddelerindeki bilgileri kullan
2. EÄŸer soruyla tam alakalÄ± bilgi yoksa, "Verilen mevzuat maddelerinde bu konuda aÃ§Ä±k bir bilgi bulamadÄ±m" de
3. CevabÄ±nÄ± TÃ¼rkÃ§e, net, anlaÅŸÄ±lÄ±r ve yapÄ±landÄ±rÄ±lmÄ±ÅŸ ÅŸekilde ver
4. Madde ve fÄ±kra numaralarÄ±nÄ± belirt
5. Gereksiz tekrar yapma, direkt cevapla
6. KaynaklarÄ± gÃ¶stermeyi unutma

CEVAP:"""

    try:
        # YENÄ° SDK ile Ã§aÄŸrÄ±
        response = client.models.generate_content(
            model=MODEL_NAME,
            contents=prompt,
            config={
                'temperature': temperature,
                'max_output_tokens': 4096,
            }
        )

        answer = response.text

        # KaynaklarÄ± ekle
        answer += "\n\n---\n\n### ğŸ“š Kaynaklar\n\n"
        for i, result in enumerate(results[:3], 1):
            doc = result['doc']
            kaynak = f"**{i}.** {doc['belge']} - Madde {doc['madde_no']}"
            if doc.get('fikra_no'):
                kaynak += f", FÄ±kra {doc['fikra_no']}"
            answer += kaynak + "\n"

        return answer

    except Exception as e:
        print(f"âŒ LLM hatasÄ±: {e}")
        return create_fallback_answer(results, query)

def create_fallback_answer(results: List[Dict], query: str) -> str:
    """Fallback: LLM olmadan cevap"""
    if not results:
        return "ÃœzgÃ¼nÃ¼m, bu konuda bilgi bulamadÄ±m."

    answer = f"### Ä°lgili Mevzuat Maddeleri\n\n"

    for i, result in enumerate(results[:3], 1):
        doc = result['doc']
        content = doc['icerik'][:500].strip()
        if len(doc['icerik']) > 500:
            content += "..."

        answer += f"#### {i}. {doc['belge']} - Madde {doc['madde_no']}\n\n"
        answer += f"{content}\n\n"
        answer += "---\n\n"

    answer += "âš ï¸  **Not:** LLM aktif deÄŸil. Gemini API key ekleyin.\n"

    return answer

# ============================================================================
# API ENDPOINTS
# ============================================================================

@app.get("/")
def read_root():
    return {
        "message": "SelÃ§uk Ãœniversitesi Mevzuat Chatbot API",
        "status": "online",
        "toplam_madde": len(all_documents),
        "llm_aktif": gemini_available,
        "model": "BERTurk + Gemini 2.5 Flash"
    }

@app.post("/chat", response_model=ChatResponse)
def chat(q: Question):
    if not q.question.strip():
        raise HTTPException(status_code=400, detail="Soru boÅŸ olamaz!")

    print(f"\n{'=' * 70}")
    print(f"ğŸ” Soru: {q.question}")
    print(f"ğŸŒ¡ï¸  Temperature: {q.temperature}")

    # GeliÅŸmiÅŸ Hybrid Search
    results = hybrid_search(q.question, q.top_k)

    if not results:
        print("âŒ HiÃ§ alakalÄ± sonuÃ§ bulunamadÄ±")
        return ChatResponse(
            question=q.question,
            answer="ÃœzgÃ¼nÃ¼m, bu konuda mevzuatlarda ilgili bilgi bulamadÄ±m. LÃ¼tfen sorunuzu farklÄ± kelimelerle ifade etmeyi deneyin veya daha spesifik bir soru sorun.",
            sources=[],
            session_id=q.session_id
        )

    print(f"ğŸ“š {len(results)} alakalÄ± sonuÃ§ bulundu:")
    for i, r in enumerate(results[:5], 1):
        doc = r['doc']
        print(f"   {i}. {doc['belge'][:60]}... - Madde {doc['madde_no']} (skor: {r['final_score']:.2f}, eÅŸleÅŸme: {r['match_count']:.1f})")

    # KaynaklarÄ± hazÄ±rla
    sources = []
    for r in results:
        doc = r['doc']
        kaynak_metni = f"{doc['belge']} - Madde {doc['madde_no']}"
        if doc.get('fikra_no'):
            kaynak_metni += f", FÄ±kra {doc['fikra_no']}"

        sources.append({
            "belge": doc['belge'],
            "madde_no": doc['madde_no'],
            "fikra_no": doc.get('fikra_no'),
            "kaynak_metni": kaynak_metni,
            "icerik": doc['icerik'][:400] + "..." if len(doc['icerik']) > 400 else doc['icerik'],
            "score": round(r['final_score'], 2)
        })

    # LLM ile cevap
    answer = create_llm_answer(results, q.question, q.temperature)

    print(f"âœ… Cevap hazÄ±r ({len(answer)} karakter)")
    print(f"{'=' * 70}\n")

    return ChatResponse(
        question=q.question,
        answer=answer,
        sources=sources,
        session_id=q.session_id
    )

@app.get("/health")
def health_check():
    return {
        "status": "healthy",
        "documents": len(all_documents),
        "llm_available": gemini_available
    }
@app.delete("/session/{session_id}")
def delete_session(session_id: str):
    """
    Session'Ä± sil (ÅŸu an sadece bilgilendirme)
    """
    print(f"ğŸ—‘ï¸  Session silindi: {session_id}")
    return {"message": "Session silindi", "session_id": session_id}

# ============================================================================
# Ã‡ALIÅTIRMA
# ============================================================================

if __name__ == "__main__":
    import uvicorn

    print("\n" + "=" * 70)
    print("ğŸš€ SelÃ§uk Ãœniversitesi Mevzuat Chatbot API v2.0")
    print("=" * 70)
    print(f"ğŸ“š Toplam Madde: {len(all_documents)}")
    print(f"ğŸ¤– Embedding: BERTurk")
    print(f"ğŸ§  LLM: {'Gemini 2.5 Flash âœ…' if gemini_available else 'Yok âŒ'}")
    print(f"ğŸ” Search: Hybrid + Smart Keyword Filtering")
    print("=" * 70)
    print("\nğŸ“¡ API: http://localhost:8000")
    print("ğŸ“– Docs: http://localhost:8000/docs\n")

    uvicorn.run(app, host="0.0.0.0", port=8000)