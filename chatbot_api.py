from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from typing import List, Dict
import os
import re
import json
from rank_bm25 import BM25Okapi
from google import genai
from dotenv import load_dotenv

load_dotenv()

# ============================================================================
# KONFIGÃœRASYON
# ============================================================================

app = FastAPI(title="Mevzuat Chatbot API")

CHROMA_DIR = "./mevzuat_db"
JSON_PATH = "tum_mevzuat_maddeleri_enriched.json"  # ğŸ†• ENRICHED kullan!

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")

# ============================================================================
# MODEL YÃœKLEMELERÄ°
# ============================================================================

print("ğŸ¤– BERTurk embedding modeli yÃ¼kleniyor...")
embeddings = HuggingFaceEmbeddings(
    model_name="dbmdz/bert-base-turkish-cased",
    model_kwargs={'device': 'cpu'},
    encode_kwargs={'normalize_embeddings': True}
)
print("âœ… BERTurk hazÄ±r!")

if not os.path.exists(CHROMA_DIR):
    raise Exception(f"âŒ ChromaDB bulunamadÄ±: {CHROMA_DIR}")

print("ğŸ“š ChromaDB yÃ¼kleniyor...")
db = Chroma(persist_directory=CHROMA_DIR, embedding_function=embeddings)
print("âœ… ChromaDB hazÄ±r!")

if not os.path.exists(JSON_PATH):
    raise Exception(f"âŒ JSON dosyasÄ± bulunamadÄ±: {JSON_PATH}")

print("ğŸ“„ Mevzuat dÃ¶kÃ¼manlarÄ± yÃ¼kleniyor...")
with open(JSON_PATH, "r", encoding="utf-8") as f:
    all_documents = json.load(f)
print(f"âœ… {len(all_documents)} madde yÃ¼klendi")

print("ğŸ“Š BM25 index oluÅŸturuluyor...")
tokenized_corpus = [doc["icerik"].lower().split() for doc in all_documents]
bm25 = BM25Okapi(tokenized_corpus)
print("âœ… BM25 hazÄ±r!")

print("ğŸ§  Gemini LLM yapÄ±landÄ±rÄ±lÄ±yor...")
try:
    client = genai.Client(api_key=GEMINI_API_KEY)
    MODEL_NAME = 'gemini-2.5-flash'
    print("âœ… Gemini LLM hazÄ±r!")
    gemini_available = True
except Exception as e:
    print(f"âŒ Gemini yapÄ±landÄ±rÄ±lamadÄ±: {e}")
    gemini_available = False


# ============================================================================
# PYDANTIC MODELLERÄ°
# ============================================================================

class Question(BaseModel):
    question: str
    session_id: str = "default"
    top_k: int = 5
    temperature: float = 0.3


class ChatResponse(BaseModel):
    question: str
    answer: str
    sources: list
    session_id: str


# ============================================================================
# YARDIMCI FONKSÄ°YONLAR
# ============================================================================

def normalize_text(text: str) -> str:
    """Metni normalize et"""
    text = text.lower()
    text = re.sub(r'[^\wÄŸÃ¼ÅŸÃ¶Ã§Ä±Ä°\s]', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text


def extract_keywords(query: str) -> List[str]:
    """
    Sorudan Ã¶nemli anahtar kelimeleri Ã§Ä±kar (stop words'leri filtrele)
    """
    stop_words = {
        'bir', 'bu', 've', 'ile', 'iÃ§in', 'mi', 'mÄ±', 'mu', 'mÃ¼',
        'da', 'de', 'ta', 'te', 'ben', 'sen', 'bana', 'sana',
        'ne', 'nedir', 'nasÄ±l', 'gibi', 'olan', 'olarak',
        'verir', 'misin', 'misiniz', 'var', 'yok', 'ÅŸey',
        'hakkÄ±nda', 'konusunda', 'ile', 'alakalÄ±', 'ilgili',
        'bilgi', 'verme', 'vermek', 'sÃ¶yle', 'anlat',
        'eder', 'olur', 'dÄ±r', 'dir', 'tir', 'tÄ±r'
    }

    words = normalize_text(query).split()
    keywords = [w for w in words if w not in stop_words and len(w) > 2]

    return keywords


def hybrid_search(query: str, top_k: int = 5) -> List[Dict]:
    """
    GeliÅŸtirilmiÅŸ Hybrid Search (BM25 + Semantic + Keyword + Metadata)
    """
    # ğŸ†• QUERY PREPROCESSING - BitiÅŸik kelimeleri ayÄ±r
    query_normalized = normalize_text(query)

    # "yandal" â†’ "yan dal" Ã§evirisi
    if 'yandal' in query_normalized:
        query_normalized = query_normalized.replace('yandal', 'yan dal')
        print(f"ğŸ”„ Query normalize edildi: 'yandal' â†’ 'yan dal'")

    # "Ã§iftanadal" / "Ã§iftanaadal" â†’ "Ã§ift anadal"
    if 'Ã§iftanadal' in query_normalized or 'Ã§iftanaadal' in query_normalized:
        query_normalized = query_normalized.replace('Ã§iftanadal', 'Ã§ift anadal')
        query_normalized = query_normalized.replace('Ã§iftanaadal', 'Ã§ift anadal')
        print(f"ğŸ”„ Query normalize edildi: 'Ã§ift anadal'")

    # ğŸ†• QUERY EXPANSION - KÄ±saltmalarÄ± geniÅŸlet
    query_expansions = {
        'cap': 'Ã§ift anadal Ã§ap',
        'Ã§ap': 'Ã§ift anadal Ã§ap',
        'gano': 'genel aÄŸÄ±rlÄ±klÄ± not ortalamasÄ±',
    }

    for short, expanded in query_expansions.items():
        if short in query_normalized:
            query_normalized = query_normalized.replace(short, expanded)
            print(f"ğŸ”„ Query geniÅŸletildi: '{short}' â†’ '{expanded}'")

    # Anahtar kelimeleri Ã§Ä±kar (normalize edilmiÅŸ query'den)
    keywords = extract_keywords(query_normalized)
    print(f"ğŸ” Anahtar kelimeler: {keywords}")

    # 1. BM25 Search (normalized keywords ile)
    bm25_scores = bm25.get_scores(keywords)

    # 2. Semantic Search (normalized query ile)
    try:
        semantic_results = db.similarity_search_with_score(query_normalized, k=top_k * 3)
    except Exception as e:
        print(f"âš ï¸  Semantic search hatasÄ±: {e}")
        semantic_results = []

    # 3. SonuÃ§larÄ± birleÅŸtir
    candidates = {}

    # BM25 sonuÃ§larÄ±
    for idx, score in enumerate(bm25_scores):
        if score > 0:
            doc_id = f"doc_{idx}"
            candidates[doc_id] = {
                'doc': all_documents[idx],
                'bm25_score': float(score),
                'semantic_score': 0.0,
                'content': all_documents[idx]['icerik']
            }

    # Semantic sonuÃ§larÄ±
    for doc, distance in semantic_results:
        content = doc.page_content
        for idx, d in enumerate(all_documents):
            if d['icerik'] == content:
                doc_id = f"doc_{idx}"
                semantic_score = 1 - distance

                if doc_id in candidates:
                    candidates[doc_id]['semantic_score'] = semantic_score
                else:
                    candidates[doc_id] = {
                        'doc': d,
                        'bm25_score': 0.0,
                        'semantic_score': semantic_score,
                        'content': content
                    }
                break

    # 4. AKILLI KEYWORD BOOST
    domain_keywords = {
        'gÃ¼z': ['gÃ¼z', 'bahar', 'dÃ¶nem', 'yarÄ±yÄ±l', 'akademik takvim'],
        'bahar': ['gÃ¼z', 'bahar', 'dÃ¶nem', 'yarÄ±yÄ±l', 'akademik takvim'],
        'baÅŸvuru': ['baÅŸvuru', 'mÃ¼racaat', 'kayÄ±t', 'kabul', 'ÅŸart', 'koÅŸul'],
        'yatay': ['yatay geÃ§iÅŸ', 'transfer'],
        'dikey': ['dikey geÃ§iÅŸ'],
        'Ã§ift': ['Ã§ift anadal', 'Ã§ap', 'ana dal'],
        'yan': ['yan dal', 'yandal'],
        'yandal': ['yan dal', 'yandal'],
        'dal': ['yan dal', 'yandal', 'ana dal'],
        'anadal': ['Ã§ift anadal', 'ana dal', 'Ã§ap'],
        'staj': ['staj', 'uygulama', 'iÅŸ yeri', 'iÅŸletme'],
        'sÄ±nav': ['sÄ±nav', 'final', 'vize', 'bÃ¼tÃ¼nleme', 'mazeret'],
        'dersi': ['ders', 'kurs', 'program', 'mÃ¼fredat'],
        'sss': ['sÄ±kÃ§a sorulan', 'soru', 'cevap'],  # ğŸ†• SSS iÃ§in
    }

    for doc_id, result in candidates.items():
        content_lower = result['content'].lower()
        belge_lower = result['doc']['belge'].lower()

        keyword_boost = 0
        match_count = 0

        # Her keyword iÃ§in kontrol
        for kw in keywords:
            # DoÄŸrudan eÅŸleÅŸme (iÃ§erikte)
            if kw in content_lower:
                match_count += 1
                keyword_boost += 2.0

            # BELGE ADINDA EÅLEÅME (Ã‡OK DEÄERLÄ°!)
            if kw in belge_lower:
                keyword_boost += 10.0
                match_count += 2
                print(f"    ğŸ¯ BELGE ADI EÅLEÅMESÄ°: '{kw}' â†’ '{result['doc']['belge'][:60]}'")

            # Domain keyword grubu eÅŸleÅŸmesi
            if kw in domain_keywords:
                related_words = domain_keywords[kw]
                for rel_word in related_words:
                    if rel_word in content_lower:
                        keyword_boost += 1.5
                        match_count += 0.5
                        break
                    if rel_word in belge_lower:
                        keyword_boost += 3.0
                        match_count += 1.0
                        break

        # EÅŸleÅŸme oranÄ±
        if keywords:
            match_ratio = match_count / len(keywords)
            keyword_boost *= match_ratio

        result['keyword_boost'] = keyword_boost
        result['match_count'] = match_count

    # 5. METADATA-BASED PRIORITY BOOST
    print("\nğŸ·ï¸  Metadata boost uygulanÄ±yor...")
    query_lower = query.lower()

    for doc_id, result in candidates.items():
        doc = result['doc']
        belge_lower = doc['belge'].lower()

        # ğŸ†• Metadata bilgilerini al (enriched JSON'dan)
        belge_tipi = doc.get('belge_tipi', 'other')
        oncelik = doc.get('oncelik', 5)
        fakulte = doc.get('fakulte')

        # KullanÄ±cÄ± fakÃ¼lte belirtmiÅŸ mi?
        fakulte_in_query = False
        if fakulte:
            fakulte_lower = fakulte.lower()
            fakulte_in_query = fakulte_lower in query_lower

        # ÃœNÄ°VERSÄ°TE GENEL â†’ BÃ¼yÃ¼k boost (fakÃ¼lte belirtilmediyse)
        if belge_tipi == 'university_general':
            if not fakulte_in_query:
                result['keyword_boost'] += 8.0
                print(f"  âœ¨ Genel yÃ¶netmelik boost: {doc['belge'][:50]}...")

        # FAKÃœLTE SPESÄ°FÄ°K â†’ EÅŸleÅŸme varsa boost, yoksa CEZA
        elif belge_tipi == 'faculty_specific':
            if fakulte_in_query:
                result['keyword_boost'] += 6.0
                print(f"  âœ… FakÃ¼lte eÅŸleÅŸti: {doc['belge'][:50]}...")
            else:
                result['keyword_boost'] -= 4.0
                print(f"  âš ï¸  FakÃ¼lte eÅŸleÅŸmedi (ceza): {doc['belge'][:50]}...")

        # PROGRAM SPESÄ°FÄ°K â†’ Normal boost
        elif belge_tipi == 'program_specific':
            result['keyword_boost'] += oncelik * 0.5

        # DÃœÅÃœK Ã–NCELÄ°K â†’ Ceza
        elif belge_tipi == 'low_priority':
            result['keyword_boost'] -= 2.0

        # ğŸ†• Ã–ncelik skorunu sakla (normalizasyon iÃ§in)
        result['priority_raw'] = oncelik

    # 6. ğŸ†• Final Skor (Metadata Ã–ncelik Dahil!)
    print("\nğŸ¯ Final skor hesaplanÄ±yor...")
    for doc_id in candidates:
        c = candidates[doc_id]

        # En az 1 keyword eÅŸleÅŸmesi olmalÄ±
        if c['match_count'] < 1:
            c['final_score'] = 0.0
            continue

        # ğŸ†• Ã–ncelik skorunu normalize et (3-10 arasÄ± â†’ 0-1 arasÄ±)
        priority_raw = c.get('priority_raw', 5)
        priority_normalized = (priority_raw - 3) / 7.0  # 3â†’0, 10â†’1
        priority_normalized = max(0, min(1, priority_normalized))  # Clamp [0,1]

        # ğŸ†• YENÄ° SCORING FORMÃœLÄ°: BM25 + Semantic + Keyword + Priority
        c['final_score'] = (
                c['bm25_score'] * 0.25 +           # BM25 aÄŸÄ±rlÄ±ÄŸÄ±
                c['semantic_score'] * 0.25 +       # Semantic aÄŸÄ±rlÄ±ÄŸÄ±
                c['keyword_boost'] * 0.30 +        # Keyword boost
                priority_normalized * 0.20         # ğŸ†• Metadata Ã¶ncelik!
        )

        # Debug iÃ§in Ã¶ncelik gÃ¶ster
        if priority_raw >= 9:
            print(f"  ğŸ”¥ YÃ¼ksek Ã¶ncelik: {c['doc']['belge'][:50]} (Ã¶ncelik: {priority_raw})")

        # ğŸ†• RELEVANCE FILTERING - Ã‡ok dÃ¼ÅŸÃ¼k skorlarÄ± kes
        if c['final_score'] < 3.5:  # Threshold dÃ¼ÅŸÃ¼rÃ¼ldÃ¼
            c['final_score'] = 0.0

    # 7. SÄ±rala ve filtrele
    sorted_results = sorted(
        [c for c in candidates.values() if c['final_score'] > 0],
        key=lambda x: x['final_score'],
        reverse=True
    )

    return sorted_results[:top_k]


def create_llm_answer(results: List[Dict], query: str, temperature: float = 0.3) -> str:
    """
    Gemini LLM ile akÄ±llÄ± cevap Ã¼ret
    """
    if not results:
        return "ÃœzgÃ¼nÃ¼m, bu konuda mevzuatlarda ilgili bilgi bulamadÄ±m. LÃ¼tfen sorunuzu farklÄ± kelimelerle ifade etmeyi deneyin."

    if not gemini_available:
        return create_fallback_answer(results, query)

    # Context hazÄ±rla
    context = ""
    for i, result in enumerate(results[:3], 1):
        doc = result['doc']
        context += f"\n\n--- KAYNAK {i} ---\n"
        context += f"Belge: {doc['belge']}\n"
        context += f"Madde No: {doc['madde_no']}\n"
        if doc.get('fikra_no'):
            context += f"FÄ±kra No: {doc['fikra_no']}\n"
        context += f"Ä°Ã§erik:\n{doc['icerik']}\n"

    # Prompt
    prompt = f"""Sen SelÃ§uk Ãœniversitesi'nin mevzuat konusunda uzman bir asistansÄ±n.

GÃ–REV: AÅŸaÄŸÄ±daki mevzuat maddelerini kullanarak kullanÄ±cÄ±nÄ±n sorusunu cevapla.

KULLANICI SORUSU:
{query}

Ä°LGÄ°LÄ° MEVZUAT MADDELERÄ°:
{context}

Ã–NEMLÄ° KURALLAR:
1. **SADECE** verilen mevzuat maddelerindeki bilgileri kullan
2. EÄŸer soruyla tam alakalÄ± bilgi yoksa, "Verilen mevzuat maddelerinde bu konuda aÃ§Ä±k bir bilgi bulamadÄ±m" de
3. CevabÄ±nÄ± TÃ¼rkÃ§e, net, anlaÅŸÄ±lÄ±r ve yapÄ±landÄ±rÄ±lmÄ±ÅŸ ÅŸekilde ver
4. Madde ve fÄ±kra numaralarÄ±nÄ± belirt
5. Gereksiz tekrar yapma, direkt cevapla
6. KaynaklarÄ± gÃ¶stermeyi unutma

CEVAP:"""

    try:
        response = client.models.generate_content(
            model=MODEL_NAME,
            contents=prompt,
            config={
                'temperature': temperature,
                'max_output_tokens': 4096,
            }
        )

        answer = response.text

        # KaynaklarÄ± ekle
        answer += "\n\n---\n\n### ğŸ“š Kaynaklar\n\n"
        for i, result in enumerate(results[:3], 1):
            doc = result['doc']
            kaynak = f"**{i}.** {doc['belge']} - Madde {doc['madde_no']}"
            if doc.get('fikra_no'):
                kaynak += f", FÄ±kra {doc['fikra_no']}"
            answer += kaynak + "\n"

        return answer

    except Exception as e:
        print(f"âŒ LLM hatasÄ±: {e}")
        return create_fallback_answer(results, query)


def create_fallback_answer(results: List[Dict], query: str) -> str:
    """Fallback: LLM olmadan cevap"""
    if not results:
        return "ÃœzgÃ¼nÃ¼m, bu konuda bilgi bulamadÄ±m."

    answer = f"### Ä°lgili Mevzuat Maddeleri\n\n"

    for i, result in enumerate(results[:3], 1):
        doc = result['doc']
        content = doc['icerik'][:500].strip()
        if len(doc['icerik']) > 500:
            content += "..."

        answer += f"#### {i}. {doc['belge']} - Madde {doc['madde_no']}\n\n"
        answer += f"{content}\n\n"
        answer += "---\n\n"

    answer += "âš ï¸  **Not:** LLM aktif deÄŸil. Gemini API key ekleyin.\n"

    return answer


# ============================================================================
# API ENDPOINTS
# ============================================================================

@app.get("/")
def read_root():
    return {
        "message": "SelÃ§uk Ãœniversitesi Mevzuat Chatbot API",
        "status": "online",
        "toplam_madde": len(all_documents),
        "llm_aktif": gemini_available,
        "model": "BERTurk + Gemini 2.5 Flash + Metadata Priority v4.0"  # ğŸ†• Versiyon gÃ¼ncellemesi
    }


@app.post("/chat", response_model=ChatResponse)
def chat(q: Question):
    if not q.question.strip():
        raise HTTPException(status_code=400, detail="Soru boÅŸ olamaz!")

    print(f"\n{'=' * 70}")
    print(f"ğŸ” Soru: {q.question}")
    print(f"ğŸŒ¡ï¸  Temperature: {q.temperature}")

    # GeliÅŸmiÅŸ Hybrid Search
    results = hybrid_search(q.question, q.top_k)

    if not results:
        print("âŒ HiÃ§ alakalÄ± sonuÃ§ bulunamadÄ±")
        return ChatResponse(
            question=q.question,
            answer="ÃœzgÃ¼nÃ¼m, bu konuda mevzuatlarda ilgili bilgi bulamadÄ±m. LÃ¼tfen sorunuzu farklÄ± kelimelerle ifade etmeyi deneyin veya daha spesifik bir soru sorun.",
            sources=[],
            session_id=q.session_id
        )

    print(f"ğŸ“š {len(results)} alakalÄ± sonuÃ§ bulundu:")
    for i, r in enumerate(results[:5], 1):
        doc = r['doc']
        # ğŸ†• Ã–ncelik skorunu da gÃ¶ster
        priority = r.get('priority_raw', 'N/A')
        print(
            f"   {i}. {doc['belge'][:60]}... - Madde {doc['madde_no']} "
            f"(skor: {r['final_score']:.2f}, Ã¶ncelik: {priority}, eÅŸleÅŸme: {r['match_count']:.1f})"
        )

    # KaynaklarÄ± hazÄ±rla
    sources = []
    for r in results:
        doc = r['doc']
        kaynak_metni = f"{doc['belge']} - Madde {doc['madde_no']}"
        if doc.get('fikra_no'):
            kaynak_metni += f", FÄ±kra {doc['fikra_no']}"

        sources.append({
            "belge": doc['belge'],
            "madde_no": doc['madde_no'],
            "fikra_no": doc.get('fikra_no'),
            "kaynak_metni": kaynak_metni,
            "icerik": doc['icerik'][:400] + "..." if len(doc['icerik']) > 400 else doc['icerik'],
            "score": round(r['final_score'], 2),
            "priority": r.get('priority_raw', 5)  # ğŸ†• Kaynakta Ã¶ncelik gÃ¶ster
        })

    # LLM ile cevap
    answer = create_llm_answer(results, q.question, q.temperature)

    print(f"âœ… Cevap hazÄ±r ({len(answer)} karakter)")
    print(f"{'=' * 70}\n")

    return ChatResponse(
        question=q.question,
        answer=answer,
        sources=sources,
        session_id=q.session_id
    )


@app.get("/health")
def health_check():
    return {
        "status": "healthy",
        "documents": len(all_documents),
        "llm_available": gemini_available
    }


@app.delete("/session/{session_id}")
def delete_session(session_id: str):
    """
    Session'Ä± sil (ÅŸu an sadece bilgilendirme)
    """
    print(f"ğŸ—‘ï¸  Session silindi: {session_id}")
    return {"message": "Session silindi", "session_id": session_id}


# ============================================================================
# Ã‡ALIÅTIRMA
# ============================================================================

if __name__ == "__main__":
    import uvicorn

    print("\n" + "=" * 70)
    print("ğŸš€ SelÃ§uk Ãœniversitesi Mevzuat Chatbot API v4.0")
    print("=" * 70)
    print(f"ğŸ“š Toplam Madde: {len(all_documents)}")
    print(f"ğŸ¤– Embedding: BERTurk")
    print(f"ğŸ§  LLM: {'Gemini 2.5 Flash âœ…' if gemini_available else 'Yok âŒ'}")
    print(f"ğŸ” Search: Hybrid + Query Normalization + Metadata Priority")
    print("=" * 70)
    print("\nğŸ“¡ API: http://localhost:8000")
    print("ğŸ“– Docs: http://localhost:8000/docs\n")

    uvicorn.run(app, host="0.0.0.0", port=8000)
